default: &DEFAULT

  #General
  verbose: True
  arch: 'fno'

  distributed:
    use_distributed: False
    wireup_info: 'mpi'
    wireup_store: 'tcp'
    model_parallel_size: 2
    seed: 666

  # FNO related
  fno:
    data_channels: 3
    n_modes: (32, 32)
    hidden_channels: 32
    projection_channels: 64
    incremental_n_modes: (2, 2)
  
  data:
    folder: /home/robert/data/navierstokes_new/
    batch_size: 3
    n_train: 1000
    train_resolution: 1024
    n_tests: [200]
    test_resolutions: [1024] #, 1024] 
    test_batch_sizes: [3] #, 1]
    positional_encoding: True

    encode_input: True
    encode_output: False
    num_workers: 0
    pin_memory: False
    persistent_workers: False

  # Optimizer
  opt:
    n_epochs: 500
    learning_rate: 1e-3
    training_loss: 'h1'
    weight_decay: 1e-4
    amp_autocast: False

    scheduler: 'CyclicLR' #'StepLR' # Or 'CosineAnnealingLR' OR 'ReduceLROnPlateau'
    step_size: 100
    gamma: 0.5
    base_lr: 1e-3
    max_lr: 1e-2
    cycle_momentum: False
    mode: "triangular2"
    last_epoch: -1
    step_size_up: 6000 # 120 * 100 //2 
    step_size_down: 6000

  # Patching
  patching:
    levels: 0
    padding: 0 #.1
    stitching: True

  # incremental paramaters
  incremental:
    incremental_grad:
      init_modes: 6
      buffer_modes: 5
      grad_explained_ratio_threshold: 0.99
      max_iter: 1
      grad_max_iter: 10
    
    incremental_loss_gap:
      init_modes: 1
      eps: 0.01

    incremental_resolution:
      epoch_gap: 100

    dataset:
      SmallDarcy: [1]
      Darcy: [8, 4, 2, 1]
      Burgers: [256, 64, 16, 8, 1]
      NavierStokes: [16, 8, 4, 2, 1]
      Vorticity: [128, 64, 32, 16, 1]

  # Weights and biases
  wandb:
    log: True
    name: navierstokes-incremental # If None, config will be used but you can override it here
    group: '' 
    project: "navierstokes-high-resolution"
    entity: "research-pino_ifno" # put your username here
    sweep: False
    log_output: True
    log_test_interval: 5

  n_params_baseline: None